'''
Created on Oct 17, 2015

@author: Ben Maxfield
'''

from time import clock
from flask import Markup
from apscheduler.schedulers.background import BackgroundScheduler
from lxml import html, etree
import requests
import feedparser

class Scraper():
    
    scheduler = None
    script = Markup('''
        > python scraper.py</br>
        STARTING WEB SCRAPER...</br>
        =========================|</br>
        000%|====================|</br>
        =========================|</br>
        </br>
        GETting first target:</br>
        address=\"https://github.com/bmaxfie\"</br>
        .</br>
        .</br>
        .</br>
        RETRIEVED .html, {} KB</br>
        PARSING .html</br>
        FOUND commit stats!</br>
        ADDED markup to front.html template</br>
        FOUND .css links!</br>
        ADDED markup to front.html template</br>
        FOUND .js links!</br>
        ADDED markup to front.html template</br>
        ANIMATING...</br>
        </br>
        GETting second target:</br>
        address=\"http://feeds.sciencedaily.com/sciencedaily/top_news/top_technology?format=xml\"</br>
        .</br>
        .</br>
        .</br>
        RETRIEVED .xml, {} KB</br>
        PARSING .xml</br>
        FOUND top 3 articles!</br>
        ADDED markup to front.html template</br>
        ANIMATING...</br>
        </br>
        =========================|</br>
        WEB SCRAPER COMPLETE</br>
        </br>
        >
        ''')
    SDtitles = ['', '', '']
    SDlinks = ['', '', '']
    SDtimestamp = 0
    GithubHTML = None
    GithubCSS = None


    def __init__(self):
        self.update()
        scheduler = BackgroundScheduler()
        scheduler.start()
        scheduler.add_job(self.update, 'interval', hours=1)
        
    def update(self):
        # Saves the top 3 article titles and links from ScienceDaily.com under the Technology category.
        feed = feedparser.parse('http://feeds.sciencedaily.com/sciencedaily/top_news/top_technology?format=xml')
        for i in range(0,3):
            self.SDtitles[i] = feed.entries[i].title
            self.SDlinks[i] = feed.entries[i].link
        self.SDtimestamp = clock()
        SDsize = feed.__sizeof__() * 100.0 / 1000 # SOMETHING IS WRONG HERE, This XML is not ~508 Bytes... its at least 5 KB.
        
        # Gets bmaxfie@Github public data and .css from page
        page = requests.get('https://github.com/bmaxfie')
        tree = html.fromstring(page.text)
        self.GithubHTML = Markup(etree.tostring(tree.xpath('//div[@class="boxed-group flush"]')[1], pretty_print=True))
        GithubSize = page.__sizeof__() * 1000.0 / 1000 # SOMETHING IS WRONG HERE, see above comment
        
        strings = ""
        for element in tree.xpath('//link[@rel="stylesheet"]'):
            strings = strings + etree.tostring(element, pretty_print=True)
        self.GithubCSS = Markup(strings)
        
        self.script = self.script.format(SDsize, GithubSize)
        
