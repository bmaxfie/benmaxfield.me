'''
Created on Oct 17, 2015

@author: Ben Maxfield
'''

from time import clock
from flask import Markup
from apscheduler.schedulers.background import BackgroundScheduler
from lxml import html, etree
import requests
import feedparser

class Scraper():
    
    scheduler = None
    script = '''
        > python scraper.py
        STARTING WEB SCRAPER...\n
        =========================|\n
        000%|====================|\n
        =========================|\n
        \n
        GETting first target:\n
        \"https://github.com/bmaxfie\"\n
        .\n
        .\n
        .\n
        RETRIEVED .html, %d KB\n
        PARSING .html\n
        FOUND commit stats!\n
        ADDED markup to front.html template\n
        FOUND .css links!\n
        ADDED markup to front.html template\n
        FOUND .js links!\n
        ADDED markup to front.html template\n
        ANIMATING...\n
        \n
        GETting second target:\n
        \"http://feeds.sciencedaily.com/sciencedaily/top_news/top_technology?format=xml\"\n
        .\n
        .\n
        .\n
        RETRIEVED .xml, %d KB\n
        PARSING .xml\n
        FOUND top 3 articles!\n
        ADDED markup to front.html template\n
        ANIMATING...\n
        \n
        =========================|\n
        WEB SCRAPER COMPLETE\n
        \n
        >
        '''
    SDtitles = ['', '', '']
    SDlinks = ['', '', '']
    SDtimestamp = 0
    GithubHTML = None
    GithubCSS = None


    def __init__(self):
        self.update()
        scheduler = BackgroundScheduler()
        scheduler.start()
        scheduler.add_job(self.update, 'interval', hours=1)
        
    def update(self):
        # Saves the top 3 article titles and links from ScienceDaily.com under the Technology category.
        feed = feedparser.parse('http://feeds.sciencedaily.com/sciencedaily/top_news/top_technology?format=xml')
        for i in range(0,3):
            self.SDtitles[i] = feed.entries[i].title
            self.SDlinks[i] = feed.entries[i].link
        self.SDtimestamp = clock()
        SDsize = feed.__sizeof__() * 10 # SOMETHING IS WRONG HERE, This XML is not ~508 Bytes... its at least 5 KB.
        
        # Gets bmaxfie@Github public data and .css from page
        page = requests.get('https://github.com/bmaxfie')
        tree = html.fromstring(page.text)
        self.GithubHTML = Markup(etree.tostring(tree.xpath('//div[@class="boxed-group flush"]')[1], pretty_print=True))
        GithubSize = page.__sizeof__() * 10
        
        strings = ""
        for element in tree.xpath('//link[@rel="stylesheet"]'):
            strings = strings + etree.tostring(element, pretty_print=True)
        self.GithubCSS = Markup(strings)
        
        args = [SDsize, GithubSize]
        format(self.script, SDsize, GithubSize)
        
